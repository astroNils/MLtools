{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51224cf5-7320-47e6-9a54-253aa1cd5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLtools import inference\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf31e9-8910-4d88-9ac6-00eb87832ed0",
   "metadata": {},
   "source": [
    "### There are two ways to make predictions:\n",
    "A. You can use the `predictions_stitching_filtering` function in the MLtools python package. <br>\n",
    "B. or you can use directly the few functions provided on the Detectron2 platform (note that this step does not include any post-processing steps, and will give you only raw predictions). \n",
    "\n",
    "In both cases, the input image(s) need(s) to be selected and the paths to the model setup and weigths need to be specified. \n",
    "\n",
    "## A. Using the function *predictions_stichting_filtering*\n",
    "### 1. Selection of a specific image (or multiple images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2261a04c-c579-4673-9c70-35eb0cb3fd73",
   "metadata": {},
   "source": [
    "#### Single image selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de7d18-2fa9-435e-9346-7ae25fceb3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tif = Path(\"/home/nilscp/tmp/tmp_pred/M1098366481.tif\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e9858-3fe4-4ed4-83a9-1cc2bc6f47ec",
   "metadata": {},
   "source": [
    "#### Multiple images selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7944cb0-14d4-4886-ae99-34b0d781ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_folder = Path(\"/home/nilscp/tmp/tmp_pred\")\n",
    "#tifs = list(input_folder.rglob(\"*.tif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f001d-9d1b-4542-ac64-6bc53e7e8c44",
   "metadata": {},
   "source": [
    "### 2. Setup of the model (load model setup and model weights)\n",
    "Be sure that you have all of the inputs needed: \n",
    "1. Model setup file\n",
    "2. Model weights\n",
    "Both of those files can be downloaded from the project's GoogleDrive (please follow the instructions at: [DOWNLOAD_DATA_BOULDERING.ipynb](./DOWNLOAD_DATA_BOULDERING.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b36eb2-222e-447a-900f-86b4caaf4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_p = Path.home()\n",
    "work_dir = home_p / \"tmp\" / \"BOULDERING\"\n",
    "model_dir = work_dir / \"best_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28dc738-c285-4bfc-be47-5d299964ad61",
   "metadata": {},
   "source": [
    "BE CAREFUL, you have to modify the first line in the `model_setup.yaml` so that the path stored in the variable `_BASE_` corresponds to the actual path on your own computer.\n",
    "```bash\n",
    "_BASE_: <$HOME_DIRECTORY>/tmp/BOULDERING/best_model/base_setup.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6717da8-9871-4a64-9715-8f639ed57f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = model_dir / \"model_setup.yaml\"\n",
    "model_weights = model_dir / \"model_weights.pth\" # correspond to iteration 54,000\n",
    "device = \"cuda\" # \"cpu\" or \"cuda\", see comment below, please run the predictions for large images on a computer with a graphical card. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dc1312-0f10-4347-a1e5-438ce616b26c",
   "metadata": {},
   "source": [
    "I would suggest you to run this function on a computer with a graphical card (e.g., \"cuda\"), as the function is not yet optimized, and takes a rather long amount of time to run. I will improve this function over time, but it may take a little bit of time..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2ed238-e0f7-4f53-991e-8426fcbe9ce2",
   "metadata": {},
   "source": [
    "### 3. predictions_stitching_filtering\n",
    "\n",
    "There are many steps in this function. Here is a small summary of what happens.\n",
    "\n",
    "#### A. Predictions for image patches having slightly different strides/shifts\n",
    "\n",
    "In order to remove predictions which are cutted at the edge of image patches (see Fig 1.), we increase the amount of overlap between image patches. There are probably different ways of doing it (which are more effective), but we are here using 6 different strides/shifts setups to cover the whole image: \n",
    "1. Stride (0, 0)  \n",
    "2. Stride (block_width/2, block_height/2)\n",
    "3. Stride (block_width/2, block_height)\n",
    "4. Stride (block_width, block_height/2)\n",
    "5. Stride (0, block_height/2)\n",
    "6. Stride (block_width/2, 0)\n",
    "\n",
    "So, if you start with an original raster/image with 200 image patches along the x-axis, and 1000 along the y-axis. There will not be only 200x1000 image patches processed but, 4x200x1000 (for the four first stride setups), and 2x(1000 + 200) for the two last setups (as the two last setups were only needed for the image patches at the edge of the original raster/image). So from a starting number of 200,000 image patches, you end up having to process 802,400 image tiles! This increase slows significantly the time it takes to process a complete single Narrow Angle Camera (NAC) or (HiRISE). We will try to improve this step in the future. <br>\n",
    "\n",
    "Note that this steps also include the tiling of the original raster/image into smaller image patches.\n",
    "\n",
    "<center><img src=\"../images/image-20230807113604998.png\"/></center>\n",
    "\n",
    "*Figure 1. Example of edge artifacts.*\n",
    "\n",
    "#### B. Select predictions only at centres of image patches (to avoid edge predictions)\n",
    "\n",
    "Now that we have predicted boulders for a large number of image patches, we need to only select the predictions we are interested in. The way we have done it is to select only boulders within X% from the center of patches. We used a value X = distance_p = 62.5%, allowing for a little bit of overlapping. \n",
    "\n",
    "**Setup 1-4** Selecting (distance_p * 100) % from centre <br>\n",
    "**Setup 5-6** Selecting all of the boulders at the top and bottommost tiles which are not covered by setup 1 to 4. <br>\n",
    "\n",
    "#### C. Remove duplicate boulders with Non-Maximum Suppresion\n",
    "\n",
    "The last step involves removing duplicate boulders with the help of non-maximum suppression (there are lot of resource on the internet about what non-maximum suppression is, e.g., [here](https://medium.com/mlearning-ai/a-deep-dive-into-non-maximum-suppression-nms-understanding-the-math-behind-object-detection-765ff48392e5)). Long story short, it is a good way to remove duplicate/overlapping predictions. \n",
    "   \n",
    "#### D. Including Test Time Augmentation (TTA) or not? \n",
    "if the flag `is_tta` is set to *True*, every image patches will be rotated in 8 potential configurations (see Fig. 2), and predictions will be made for each of the rotation. Including TTA allows for the detection of additional boulders in image patches, however, it further increases the number of processed image patches by 8 (8 x 802,400 = 6,419,200). From the test we have run, TTA is increasing the detection rate by a few %. More test need to be conducted to contrain a bit more this value. Note that Non-Maximum Suppresion is again used to remove duplicated, and keep only the predictions with the highest score/confidence. <br>\n",
    "\n",
    "After running the function, you end up with a shapfile with no edge artificats (Fig. 3). \n",
    "\n",
    "<center><img src=\"../images/image-20230807120317504.png\"/></center>\n",
    "\n",
    "*Figure 2. 8 potential rotation transformations for an image (source: Albumentation doc).*\n",
    "\n",
    "<center><img src=\"../images/predictions_150ms.gif\" width=\"750\"/></center>\n",
    "\n",
    "\n",
    "*Figure 3. Example of a prediction at Courtright Reservoir (California, USA).*\n",
    "\n",
    "#### Variables in function:\n",
    "**in_raster**: path to original raster (which will eventually be tiled) <br>\n",
    "**config_file**: path to config file of the Mask R-CNN model. <br>\n",
    "**model_weights**: path to weights of the trained model. <br>\n",
    "**device**: \"cpu\" or \"cuda\", depending if you have a graphical card on your workstation. <br>\n",
    "**search_tif_pattern**: Not sure if this is useful, but it allows you to select tif files with a specific pattern, in case you have a folder with different tif names (e.g., \"*.tif\"). <br>\n",
    "**distance_p**: Distance from centres of image patches for which predictions are selected. <br>\n",
    "**block_width**: Width (in pixels) of image patches. <br>\n",
    "**block_height**: Height (in pixels) of image patches.<br>\n",
    "**output_dir**: Output directory for prediction shapefiles. <br>\n",
    "**is_tta**: if True, 8 rotations are applied to each patch to increase the detection rate of boulders. <br>\n",
    "**scores_thresh_test**: The score threshold. Predictions having scores below this threshold are automatically removed. <br>\n",
    "**nms_thresh_test**: Non-Maximum Suppresion threshold. Overlapping predictions having an Intersection of Union value (IoU) above this threshold are  <br>\n",
    "**min_size_test**: If you want to rescale the image (to larger dimensions). <br>\n",
    "**max_size_test**: If you want to rescale the image (to larger dimensions). <br>\n",
    "**pre_nms_topk_test**: Number of candidates predictions kepts before NMS is applied. <br>\n",
    "**post_nms_topk_test**: Number of candidates predictions kepts after NMS is applied. <br>\n",
    "**detections_per_image**: Maximum number of detections per image patch. <br>\n",
    "\n",
    "#### Good default values\n",
    "(distance_p=0.625, scores_thresh_test=0.10, nms_thresh_test=0.30, min_size_test=512, max_size_test=512, pre_nms_topk_test=2000, post_nms_topk_test=1000, detections_per_image=2000) <br>\n",
    "\n",
    "`scores_thresh_test` and `nms_thresh_test` are the two most important values. \n",
    "\n",
    "#### A few tips and tricks\n",
    "As the environments of different planetary bodies can be very different, I would advice you to run predictions with a low value for `scores_thresh_test`, like 0.1. And to then have a look at predictions in QGIS or ArcGIS. Try to play with the symbology of predictions so that different colors can be shown based on their scores. This will help you get a feeling of what a good cutoff threshold is for `scores_thresh_test`. From the different tests we have run, `scores_thresh_test` is usually taken between 0.2 and 0.5. Keeping `scores_thresh_test` variable allows for better boulder detection rate. <br>   \n",
    "\n",
    "#### Going through an example\n",
    "Let's download a small image (portion of NAC image XX, 9 image patches of 512x512 pixels) and run predictions on it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317cbf7-c3f2-4acc-b102-dd9fc69c8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_raw_inputs = \"https://drive.google.com/uc?id=10EJPATaMdS82jKOFR7rZ6o5fT6mSIhdu\"\n",
    "gdown.download(url_raw_inputs, (work_dir / \"raw_data_BOULDERING.zip\").as_posix(), quiet=True)\n",
    "\n",
    "# only work for Linux or UNIX machine (for Windows user, you can unzip the folder manually)\n",
    "!unzip ~/tmp/BOULDERING/raw_data_BOULDERING.zip -d ~/tmp/BOULDERING/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9c3e8-ccc5-465a-a285-0e4756509e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_p = Path.home()\n",
    "work_dir = home_p / \"tmp\" / \"BOULDERING\"\n",
    "model_dir = work_dir / \"best_model\"\n",
    "config_file = model_dir / \"model_setup_v050.yaml\"\n",
    "model_weights = model_dir / \"model_weights.pth\" # correspond to iteration 54,000\n",
    "device = \"cpu\" # \"cpu\" or \"cuda\", see comment below, please run the predictions for large images on a computer with a graphical card. \n",
    "\n",
    "block_width = 512\n",
    "block_height = 512\n",
    "output_dir = Path(\"\") \n",
    "is_tta = False # so that it can be run on a CPU! \n",
    "scores_thresh_test = 0.10\n",
    "nms_thresh_test = 0.30\n",
    "min_size_test = 512\n",
    "max_size_test = 512\n",
    "pre_nms_topk_test = 2000\n",
    "post_nms_topk_test = 1000\n",
    "detections_per_image = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6572a9-d692-4e84-8796-e9bebfa454ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.predictions_stitching_filtering(in_raster, config_file, model_weights,\n",
    "                                    device, search_tif_pattern, distance_p,\n",
    "                                    block_width, block_height, output_dir, is_tta=True,\n",
    "                                    scores_thresh_test=0.10,\n",
    "                                    nms_thresh_test=0.30,\n",
    "                                    min_size_test=512, max_size_test=512,\n",
    "                                    pre_nms_topk_test=2000,\n",
    "                                    post_nms_topk_test=1000,\n",
    "                                    detections_per_image=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ea5181-112b-4962-ac94-790c78c436a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4184617-2dd0-46d0-aa41-a7d0f709c2ca",
   "metadata": {},
   "source": [
    "## B. Raw predictions with Detectron2 functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd540c3-0b23-4f5b-871c-a43580f72096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
